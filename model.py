# generated by datamodel-codegen:
#   filename:  watsonx-ai.json
#   timestamp: 2024-08-09T15:35:13+00:00

from __future__ import annotations

from datetime import date, datetime
from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Extra, Field, PositiveInt, confloat, conint, constr


class TextGenCommon(BaseModel):
    input: str = Field(
        ...,
        description='The prompt to generate completions.\nNote: The method tokenizes the input internally.\nIt is recommended not to leave any trailing spaces.\n',
    )


class SpaceId(BaseModel):
    __root__: constr(regex=r'[a-zA-Z0-9-]*', min_length=36, max_length=36) = Field(
        ...,
        description='The space that contains the resource.\nEither `space_id` or `project_id` has to be given.\n',
        example='3fc54cf1-252f-424b-b52d-5cdd9814987f',
    )


class ProjectId(BaseModel):
    __root__: constr(regex=r'[a-zA-Z0-9-]*', min_length=36, max_length=36) = Field(
        ...,
        description='The project that contains the resource.\nEither `space_id` or `project_id` has to be given.\n',
        example='12ac4cf1-252f-424b-b52d-5cdd9814987f',
    )


class TextGenLengthPenalty(BaseModel):
    decay_factor: Optional[confloat(gt=1.0)] = Field(
        None,
        description='Represents the factor of exponential decay.\nLarger values correspond to more aggressive decay.\n',
        example=2.5,
    )
    start_index: Optional[conint(ge=0)] = Field(
        None,
        description='A number of generated tokens after which this should take effect.\n',
        example=5,
    )


class ParameterTruncateInputTokensFromStart(BaseModel):
    __root__: conint(ge=1) = Field(
        ...,
        description='Represents the maximum number of input tokens accepted.\nThis can be used to avoid requests failing due to input being longer than configured limits. If the text is truncated, then it truncates the start of the input (on the left), so the end of the input will remain the same.\nIf this value exceeds the `maximum sequence length` (refer to the documentation to find this value for the model) then the call will fail if the total number of tokens exceeds the `maximum sequence length`.\n',
    )


class ReturnOptionProperties(BaseModel):
    input_text: Optional[bool] = Field(
        False,
        description='Include input text in the `generated_text` field.\n',
        example=True,
    )
    generated_tokens: Optional[bool] = Field(
        False,
        description='Include the list of individual generated tokens.\nExtra token information is included based on the other flags below.\n',
        example=True,
    )
    input_tokens: Optional[bool] = Field(
        False,
        description='Include the list of input tokens. Extra token information is included based\non the other flags here, but only for decoder-only models.\n',
        example=True,
    )
    token_logprobs: Optional[bool] = Field(
        False,
        description='Include logprob (natural log of probability) for each returned token.\nApplicable only if generated_tokens == true and/or input_tokens == true.\n',
        example=True,
    )
    token_ranks: Optional[bool] = Field(
        False,
        description='Include rank of each returned token.\nApplicable only if generated_tokens == true and/or input_tokens == true.\n',
        example=True,
    )
    top_n_tokens: Optional[conint(ge=0)] = Field(
        None,
        description='Include top n candidate tokens at the position of each returned token.\nThe maximum value permitted is 5, but more may be returned if there is a tie for nth place.\nApplicable only if generated_tokens == true and/or input_tokens == true.\n',
        example=2,
    )


class DecodingMethod(Enum):
    sample = 'sample'
    greedy = 'greedy'


class TextGenParameters(BaseModel):
    decoding_method: Optional[DecodingMethod] = Field(
        'sample',
        description='Represents the strategy used for picking the tokens during generation of the output text.\n\nDuring text generation when parameter value is set to greedy, each successive token corresponds\nto the highest probability token given the text that has already been generated.\nThis strategy can lead to repetitive results especially for longer output sequences.\nThe alternative sample strategy generates text by picking subsequent tokens based on the\nprobability distribution of possible next tokens defined by (i.e., conditioned on) the\nalready-generated text and the top_k and top_p parameters described below.\nSee this [url](https://huggingface.co/blog/how-to-generate) for an informative article about text generation.\n',
        example='greedy',
    )
    length_penalty: Optional[TextGenLengthPenalty] = None
    max_new_tokens: Optional[conint(ge=0)] = Field(
        20,
        description='The maximum number of new tokens to be generated.\nThe maximum supported value for this field depends on the model being used.\n\nHow the "token" is defined depends on the tokenizer and vocabulary size,\nwhich in turn depends on the model. Often the tokens are a mix of full words and sub-words.\nTo learn more about tokenization, [see here](https://huggingface.co/course/chapter2/4).\n\nDepending on the users plan, and on the model being used, there may be an enforced maximum number of new tokens.\n',
        example=30,
    )
    min_new_tokens: Optional[conint(ge=0)] = Field(
        0,
        description='If stop sequences are given, they are ignored until minimum tokens are generated.\n',
        example=5,
    )
    random_seed: Optional[conint(ge=1)] = Field(
        None,
        description='Random number generator seed to use in sampling mode for experimental repeatability.\n',
        example=1,
    )
    stop_sequences: Optional[List[str]] = Field(
        None,
        description='Stop sequences are one or more strings which will cause the text generation to stop if/when they are produced as part of the output.\nStop sequences encountered prior to the minimum number of tokens being generated will be ignored.\n',
        example=['fail'],
        max_items=6,
        min_items=0,
        unique_items=True,
    )
    temperature: Optional[confloat(ge=0.0, le=2.0)] = Field(
        1,
        description='A value used to modify the next-token probabilities in sampling mode.\nValues less than 1.0 sharpen the probability distribution, resulting in "less random" output.\nValues greater than 1.0 flatten the probability distribution, resulting in "more random" output.\nA value of 1.0 has no effect.\n',
        example=1.5,
    )
    time_limit: Optional[PositiveInt] = Field(
        None,
        description='Time limit in milliseconds - if not completed within this time, generation will stop.\nThe text generated so far will be returned along with the TIME_LIMIT stop reason.\n\nDepending on the users plan, and on the model being used, there may be an enforced maximum time limit.\n',
        example=600000,
    )
    top_k: Optional[conint(ge=1, le=100)] = Field(
        None,
        description='The number of highest probability vocabulary tokens to keep for top-k-filtering.\nOnly applies for sampling mode. When decoding_strategy is set to sample,\nonly the top_k most likely tokens are considered as candidates for the next generated token.\n',
        example=50,
    )
    top_p: Optional[confloat(le=1.0, gt=0.0)] = Field(
        1,
        description='Similar to top_k except the candidates to generate the next token are the most likely tokens\nwith probabilities that add up to at least top_p. Also known as nucleus sampling.\nA value of 1.0 is equivalent to disabled.\n',
        example=0.5,
    )
    repetition_penalty: Optional[confloat(ge=1.0, le=2.0)] = Field(
        1,
        description='Represents the penalty for penalizing tokens that have already been generated or\nbelong to the context. The value 1.0 means that there is no penalty.\n',
        example=1.5,
    )
    truncate_input_tokens: Optional[ParameterTruncateInputTokensFromStart] = None
    return_options: Optional[ReturnOptionProperties] = None
    include_stop_sequence: Optional[bool] = Field(
        True,
        description='Pass `false` to omit matched stop sequences from the end of the output text.\nThe default is `true`, meaning that the output will end with the stop sequence text when matched.\n',
    )


class TextModeration(BaseModel):
    enabled: Optional[bool] = Field(
        True,
        description='Should this moderation be enabled on the text.\n\n\nThe default value is `true` which means that if the parent object exists\nbut the `enabled` field does not exist then this is considered to be enabled.\n',
    )
    threshold: Optional[confloat(ge=0.0, le=1.0)] = Field(
        None, description='The threshold probability that this is a real match.\n'
    )


class ModerationProperties(BaseModel):
    input: Optional[TextModeration] = None
    output: Optional[TextModeration] = None


class MaskProperties(BaseModel):
    remove_entity_value: Optional[bool] = Field(
        False,
        description='If this field is `true` then the entity value, that contains the text that was masked,\nwill also be removed from the output.\n',
    )


class HapProperties(BaseModel):
    mask: Optional[MaskProperties] = None


class ModerationHapProperties(ModerationProperties, HapProperties):
    pass


class PiiProperties(BaseModel):
    mask: Optional[MaskProperties] = None


class ModerationPiiProperties(ModerationProperties, PiiProperties):
    pass


class ModerationTextRange(BaseModel):
    start: conint(ge=0) = Field(..., description='The start index of the range.\n')
    end: conint(ge=0) = Field(
        ...,
        description='The end index of the range. The end index is exclusive meaning that the character at this index will not be included in the range.\n',
    )


class Moderations(BaseModel):
    hap: Optional[ModerationHapProperties] = None
    pii: Optional[ModerationPiiProperties] = None
    input_ranges: Optional[List[ModerationTextRange]] = Field(
        None,
        description='If set, then only these ranges will be applied to the moderations. This is useful in the case that certain parts of the input text have already been checked.\n',
    )


class TextGenRequest(TextGenCommon):
    model_id: str = Field(
        ...,
        description='The `id` of the model to be used for this request.\nPlease refer to the [list of models](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx).\n',
        example='google/flan-ul2',
    )
    space_id: Optional[SpaceId] = None
    project_id: Optional[ProjectId] = None
    parameters: Optional[TextGenParameters] = None
    moderations: Optional[Moderations] = None


class CreatedAt(BaseModel):
    __root__: datetime = Field(
        ..., description='The time when the response was created.\n'
    )


class TextGenStopReason(Enum):
    not_finished = 'not_finished'
    max_tokens = 'max_tokens'
    eos_token = 'eos_token'
    cancelled = 'cancelled'
    time_limit = 'time_limit'
    stop_sequence = 'stop_sequence'
    token_limit = 'token_limit'
    error = 'error'


class TextGenResult(BaseModel):
    generated_text: str = Field(
        ...,
        description='The text that was generated by the model.\n',
        example='Swimwear Unlimited- Mid-Summer Sale! ...',
    )
    stop_reason: TextGenStopReason


class TextGenTopTokenInfo(BaseModel):
    text: Optional[str] = Field(None, description='The token text.\n')
    logprob: Optional[float] = Field(
        None, description='The natural log of probability for the token.\n'
    )


class TextGenTokenInfo(BaseModel):
    text: Optional[str] = Field(None, description='The token text.\n')
    logprob: Optional[float] = Field(
        None, description='The natural log of probability for the token.\n'
    )
    rank: Optional[int] = Field(
        None, description='The rank of the token relative to the other tokens.\n'
    )
    top_tokens: Optional[List[TextGenTopTokenInfo]] = Field(
        None, description='The top tokens.\n', min_items=0
    )


class TextGenResultFields(BaseModel):
    generated_token_count: Optional[int] = Field(
        None, description='The number of generated tokens.\n', example=3
    )
    input_token_count: Optional[int] = Field(
        None, description='The number of input tokens consumed.\n', example=11
    )
    seed: Optional[int] = Field(
        None, description='The seed used, if it exists.\n', example=42
    )
    generated_tokens: Optional[List[TextGenTokenInfo]] = Field(
        None,
        description='The list of individual generated tokens.\nExtra token information is included based on the other flags in the `return_options` of the request.\n',
        example=[
            {
                'text': '_',
                'rank': 1,
                'logprob': -2.5,
                'top_tokens': [
                    {'text': '_', 'logprob': -2.5},
                    {'text': '_2', 'logprob': -3.1777344},
                ],
            },
            {
                'text': '4,000',
                'rank': 1,
                'logprob': -3.0957031,
                'top_tokens': [
                    {'text': '4,000', 'logprob': -3.0957031},
                    {'text': '57', 'logprob': -3.3691406},
                ],
            },
        ],
        min_items=1,
    )
    input_tokens: Optional[List[TextGenTokenInfo]] = Field(
        None,
        description='The list of input tokens.\nExtra token information is included based on the other flags in the `return_options` of the request, but for decoder-only models.\n',
        example=[{'text': '_how'}, {'text': '_far'}, {'text': '_is'}, {'text': '</s>'}],
        min_items=1,
    )


class Result(TextGenResult, TextGenResultFields):
    pass


class TextGenResponseFields(BaseModel):
    model_id: str = Field(
        ...,
        description='The `id` of the model for inference.\n',
        example='google/flan-ul2',
    )
    model_version: Optional[
        constr(regex=r'^\d+.\d+.\d+$', min_length=5, max_length=20)
    ] = Field(
        None,
        description='The model version (using semantic versioning) if set.\n',
        example='1.0.1',
    )
    created_at: CreatedAt
    results: List[Result] = Field(
        ..., description='The generated tokens.\n', min_items=1
    )


class Warning(BaseModel):
    message: str = Field(
        ..., description='The message.\n', example='The framework TF 1.1 is deprecated.'
    )
    id: Optional[str] = Field(
        None,
        description='An `id` associated with the message.\n',
        example='2fc54cf1-252f-424b-b52d-5cdd98149871',
    )
    more_info: Optional[str] = Field(
        None, description='A reference to a more detailed explanation when available.\n'
    )
    additional_properties: Optional[Dict[str, Any]] = Field(
        None,
        description='Additional key-value pairs that depend on the specific warning.\n',
    )


class SystemDetails(BaseModel):
    warnings: Optional[List[Warning]] = Field(
        None, description='Any warnings coming from the system.\n'
    )


class System(BaseModel):
    system: Optional[SystemDetails] = None


class TextGenResponse(TextGenResponseFields, System):
    pass


class Type(Enum):
    field = 'field'
    query = 'query'
    header = 'header'


class ApiErrorTarget(BaseModel):
    type: Type = Field(..., description='The type of the problematic field.\n')
    name: str = Field(..., description='The name of the problematic field.\n')


class ApiError(BaseModel):
    code: str = Field(
        ...,
        description='A simple code that should convey the general sense of the error.\n',
        example='missing_field',
    )
    message: str = Field(
        ...,
        description='The message that describes the error.\n',
        example="The 'name' field is required.",
    )
    more_info: Optional[str] = Field(
        None,
        description='A reference to a more detailed explanation when available.\n',
        example='https://cloud.ibm.com/apidocs/machine-learning#models-get',
    )
    target: Optional[ApiErrorTarget] = None


class ApiErrorResponse(BaseModel):
    trace: str = Field(
        ...,
        description='An identifier that can be used to trace the request.\n',
        example='3fd543d2-36e0-4f83-9be3-5c6dd498af4f',
    )
    errors: List[ApiError] = Field(..., description='The list of errors.\n')


class TextGenStreamResponse(BaseModel):
    __root__: List[TextGenResponse] = Field(
        ...,
        description='A set of server sent events, each event contains a response for one or more tokens. The results will be an array of events of the form `data: {<json event>}` where the schema of the individual `json event` is described below.\n',
    )


class TextTokenizeParameters(BaseModel):
    return_tokens: Optional[bool] = Field(
        False,
        description='If this is `true` then the actual tokens will also be returned in the response.\n',
        example=True,
    )


class TextTokenizeRequest(BaseModel):
    space_id: Optional[SpaceId] = None
    project_id: Optional[ProjectId] = None
    model_id: str = Field(
        ...,
        description='The `id` of the model to be used for this request.\nPlease refer to the [list of models](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx).\n',
        example='google/flan-ul2',
    )
    input: str = Field(
        ...,
        description='The input string to tokenize.\n',
        example='Write a tagline for an alumni association: Together we',
    )
    parameters: Optional[TextTokenizeParameters] = None


class TextTokenizeResult(BaseModel):
    token_count: int = Field(
        ..., description='The number of tokens in the input string.\n', example=11
    )
    tokens: Optional[List[str]] = Field(
        None,
        description='The input string broken up into the tokens, if requested.\n',
        example=[
            'Write',
            'a',
            'tag',
            'line',
            'for',
            'an',
            'alumni',
            'associ',
            'ation:',
            'Together',
            'we',
        ],
    )


class TextTokenizeResponse(BaseModel):
    model_id: str = Field(
        ...,
        description='The `id` of the model to be used for this request.\nPlease refer to the [list of models](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx).\n',
        example='google/flan-ul2',
    )
    result: TextTokenizeResult


class PaginationFirst(BaseModel):
    href: str = Field(..., description='The uri of the first resource returned.\n')


class PaginationNext(BaseModel):
    href: str = Field(..., description='The uri of the next set of resources.\n')


class PaginationBase(BaseModel):
    total_count: Optional[int] = Field(
        None,
        description="Computed explicitly only when 'total_count=true' query parameter is present.\nThis is in order to avoid performance penalties.\n",
    )
    limit: conint(ge=1, le=200) = Field(
        ..., description='The number of items to return in each page.\n', example=10
    )
    first: PaginationFirst
    next: Optional[PaginationNext] = None


class PaginationTC(PaginationBase):
    total_count: Optional[int] = Field(
        None, description='The total number of resources.\n', example=1
    )


class ConsumptionsLimit(BaseModel):
    call_time: Optional[str] = Field(
        None,
        description='The hard limit on the call time for a request, if set.\n',
        example='3S',
    )
    max_input_tokens: Optional[int] = Field(
        None,
        description='The hard limit on the number of input tokens for a request, if set.\nA value of zero will disable this feature.\n',
        example=200,
    )
    max_output_tokens: Optional[int] = Field(
        None,
        description='The hard limit on the number of output tokens for a request, if set.\nA value of zero will disable this feature.\n',
        example=1000,
    )


class FoundationModelLimits(BaseModel):
    lite: Optional[ConsumptionsLimit] = None


class TaskRating(BaseModel):
    cost: Optional[conint(ge=1, le=5)] = Field(
        None,
        description="A metric that indicates the cost expected to be incurred by the model's support of an inference task,\nin terms of resource consumption and processing time,\non a scale of 1 to 5, where 5 is the least cost and 1 is the most cost.\nA missing value means that the cost is not known.\n",
        example=2,
    )
    quality: Optional[conint(ge=1, le=5)] = Field(
        None,
        description="A metric that indicates the quality of the model's support of an inference task,\non a scale of 1 to 5, where 5 is the best support and 1 is poor support.\nA missing value means that the quality is not known.\n",
        example=3,
    )


class TaskDescription(BaseModel):
    id: str = Field(..., description='The `id` of the task.\n', example='summarization')
    ratings: Optional[TaskRating] = None
    tags: Optional[List[str]] = Field(None, description='The tags for a given task.\n')


class FoundationModelTier(Enum):
    class_1 = 'class_1'
    class_2 = 'class_2'
    class_3 = 'class_3'
    class_c1 = 'class_c1'


class ModelLimits(BaseModel):
    max_sequence_length: Optional[int] = Field(
        None,
        description='This is the maximum allowed value for the number of tokens in the input\nprompt plus the number of tokens in the output generated by the model.\n',
        example=4096,
    )
    training_data_max_records: Optional[int] = Field(
        None,
        description='This is the maximum number of records that can be accepted when training this model.\n',
        example=1024,
    )


class Id(Enum):
    available = 'available'
    deprecated = 'deprecated'
    constricted = 'constricted'
    withdrawn = 'withdrawn'


class LifeCycleState(BaseModel):
    id: Id = Field(
        ...,
        description='The possible lifecycle stages, in order, are described below:\n\n- `available`: this means that the model is available for use.\n- `deprecated`: this means that the model is still available but the model will be removed soon, so an alternative model should be used.\n- `constricted`: this means that the model is still available for inferencing but cannot be used for training or in a deployment. The model will be removed soon so an alternative model should be used.\n- `withdrawn`: this means that the model is no longer available, check the `alternative_model_ids` to see what it can be replaced by.\n',
        example='available',
    )
    label: Optional[str] = Field(
        None, description='An optional label that may be used in the UI.\n'
    )
    start_date: Optional[date] = Field(
        None,
        description='The date (ISO 8601 format YYYY-MM-DD) when this lifecycle stage starts.\n',
        example='2023-07-23',
    )
    alternative_model_ids: Optional[List[str]] = Field(
        None,
        description='Alternative models, or model versions, that can be used instead of this model.\n',
    )
    url: Optional[str] = Field(
        None,
        description='A link to the documentation specifying details on the lifecycle plan for this model.\n',
    )


class TrainingInitMethod(BaseModel):
    supported: Optional[List[str]] = Field(
        None,
        description='The supported initialization methods.\n',
        example=['random', 'text'],
    )
    default: Optional[str] = Field(
        None,
        description='The default value, which will be one of the values from the `supported` field.\n',
        example='random',
    )


class TrainingInitText(BaseModel):
    default: Optional[str] = Field(
        None, description='Initialization text.\n', example='text'
    )


class TrainingNumVirtualTokens(BaseModel):
    supported: Optional[List[int]] = Field(
        None,
        description='The possible values for the number of virtual tokens.\n',
        example=[20, 50, 100],
    )
    default: Optional[int] = Field(
        None, description='The default number of virtual tokens.\n', example=100
    )


class TrainingNumEpochs(BaseModel):
    default: Optional[int] = Field(None, description='The default value.\n', example=20)
    min: Optional[int] = Field(None, description='The minimum value.\n', example=1)
    max: Optional[int] = Field(None, description='The maximum value.\n', example=50)


class TrainingVerbalizer(BaseModel):
    default: Optional[str] = Field(
        None,
        description='The default verbalizer.\n',
        example='Input: {{input}} Output:',
    )


class TrainingBatchSize(BaseModel):
    default: Optional[int] = Field(None, description='The default value.\n', example=16)
    min: Optional[int] = Field(None, description='The minimum value.\n', example=1)
    max: Optional[int] = Field(None, description='The maximum value.\n', example=16)


class TrainingMaxInputTokens(BaseModel):
    default: Optional[int] = Field(
        None, description='The default value.\n', example=256
    )
    min: Optional[int] = Field(None, description='The minimum value.\n', example=1)
    max: Optional[int] = Field(None, description='The maximum value.\n', example=1024)


class TrainingMaxOutputTokens(BaseModel):
    default: Optional[int] = Field(
        None, description='The default value.\n', example=128
    )
    min: Optional[int] = Field(None, description='The minimum value.\n', example=1)
    max: Optional[int] = Field(None, description='The maximum value.\n', example=256)


class TrainingTorchDtype(BaseModel):
    default: Optional[str] = Field(
        None, description='The datatype.\n', example='bfloat16'
    )


class TrainingAccumulatedSteps(BaseModel):
    default: Optional[int] = Field(
        None, description='The default value.\n', example=128
    )
    min: Optional[int] = Field(None, description='The minimum value.\n', example=1)
    max: Optional[int] = Field(None, description='The maximum value.\n', example=128)


class TrainingLearningRate(BaseModel):
    default: Optional[float] = Field(
        None, description='The default value.\n', example=0.3
    )
    min: Optional[float] = Field(None, description='The minimum value.\n', example=0.01)
    max: Optional[float] = Field(None, description='The maximum value.\n', example=0.5)


class TrainingParameters(BaseModel):
    init_method: Optional[TrainingInitMethod] = None
    init_text: Optional[TrainingInitText] = None
    num_virtual_tokens: Optional[TrainingNumVirtualTokens] = None
    num_epochs: Optional[TrainingNumEpochs] = None
    verbalizer: Optional[TrainingVerbalizer] = None
    batch_size: Optional[TrainingBatchSize] = None
    max_input_tokens: Optional[TrainingMaxInputTokens] = None
    max_output_tokens: Optional[TrainingMaxOutputTokens] = None
    torch_dtype: Optional[TrainingTorchDtype] = None
    accumulate_steps: Optional[TrainingAccumulatedSteps] = None
    learning_rate: Optional[TrainingLearningRate] = None


class FoundationModelVersion(BaseModel):
    version: Optional[constr(regex=r'^\d+.\d+.\d+$', min_length=5, max_length=20)] = (
        Field(
            None,
            description='The version of the model. This must follow semantic versioning semantics.\n',
            example='1.1.0',
        )
    )
    available_date: Optional[date] = Field(
        None,
        description='The date (ISO 8601 format YYYY-MM-DD) when this version first became available.\n',
        example='2023-08-23',
    )


class FoundationModel(BaseModel):
    model_id: str = Field(
        ..., description='The id of the foundation model.\n', example='google/flan-ul2'
    )
    label: str = Field(
        ...,
        description='A short label that will be displayed in the UI.\n',
        example='flan-ul2 (20B)',
    )
    provider: str = Field(
        ..., description='The provider of the model.\n', example='Hugging Face'
    )
    tuned_by: Optional[str] = Field(
        None, description='The organization or person that tuned this model.\n'
    )
    short_description: str = Field(
        ...,
        description='A short description of the model suitable for a title.\n',
        example='An encoder decoder model based on the T5 architecture and instruction-tuned using the Fine-tuned LAnguage Net.',
    )
    long_description: Optional[str] = Field(
        None,
        description='A longer description of the model, that may be used if no `description_url` is provided.\n',
        example='flan-ul2 (20B) is an encoder decoder model based on the T5 architecture and instruction-tuned using the Fine-tuned LAnguage Net (FLAN).',
    )
    limits: Optional[FoundationModelLimits] = None
    task_ids: Optional[List[str]] = Field(
        None, description='Deprecated: please use `tasks` instead.\n'
    )
    tasks: Optional[List[TaskDescription]] = Field(
        None,
        description='The tasks that are supported by this model.\n',
        example=[
            {'id': 'summarization', 'ratings': {'cost': 2, 'quality': 3}},
            {'id': 'classification', 'ratings': {'cost': 4, 'quality': 2}},
        ],
        min_items=1,
    )
    input_tier: FoundationModelTier
    output_tier: FoundationModelTier
    source: str = Field(
        ...,
        description='Specifies the provider of this model.\n',
        example='Hugging Face',
    )
    min_shot_size: Optional[conint(ge=0)] = Field(
        None,
        description='The minimum number of examples required for the model.\n',
        example=10,
    )
    number_params: str = Field(
        ...,
        description='The number of parameters used for the model,\nit will accept `m` for million, `b` for billion and `t` for trillion.\n',
        example='20b',
    )
    model_limits: Optional[ModelLimits] = None
    lifecycle: Optional[List[LifeCycleState]] = Field(
        None,
        description='The information related to the lifecycle of this model.\n',
        min_items=0,
    )
    training_parameters: Optional[TrainingParameters] = None
    versions: Optional[List[FoundationModelVersion]] = Field(
        None,
        description='The information related to the minor versions of this model.\n',
        min_items=0,
    )


class FoundationModelsArray(BaseModel):
    __root__: List[FoundationModel] = Field(
        ..., description='The supported foundation models.\n'
    )


class FoundationModels(PaginationTC, System):
    resources: Optional[FoundationModelsArray] = None


class FoundationModelTask(BaseModel):
    task_id: str = Field(
        ..., description='The id of the task.\n', example='summarization'
    )
    label: str = Field(
        ..., description='The label of the task.\n', example='Summarization'
    )
    description: Optional[str] = Field(
        None,
        description='The description of the task.\n',
        example='Models that are able to summarize documents based on some criteria.',
    )
    rank: int = Field(
        ..., description='The rank of the task that is mainly for the UI.\n', example=1
    )


class FoundationModelTasksArray(BaseModel):
    __root__: List[FoundationModelTask] = Field(
        ..., description='The supported foundation model tasks.\n'
    )


class FoundationModelTasks(PaginationTC, System):
    resources: Optional[FoundationModelTasksArray] = None


class Pagination(PaginationBase):
    total_count: Optional[int] = Field(
        None,
        description="The total number of resources.\nComputed explicitly only when 'total_count=true' query parameter is present.\nThis is in order to avoid performance penalties.\n",
        example=1,
    )


class ResourceMetaSimple(BaseModel):
    id: str = Field(..., description='The id of the resource.\n')
    created_at: datetime = Field(
        ..., description='The time when the resource was created.\n'
    )


class Tags(BaseModel):
    __root__: List[str] = Field(
        ..., description='A list of tags for this resource.\n', example=['t1', 't2']
    )


class ResourceCommitInfo(BaseModel):
    committed_at: datetime = Field(
        ..., description='The time when the revision was committed.\n'
    )
    commit_message: Optional[str] = Field(
        None,
        description='The message that was provided when the revision was created.\n',
    )


class ResourceMetaBase(BaseModel):
    rev: Optional[str] = Field(None, description='The revision of the resource.\n')
    owner: Optional[str] = Field(
        None, description='The user id which created this resource.\n'
    )
    modified_at: Optional[datetime] = Field(
        None, description='The time when the resource was last modified.\n'
    )
    parent_id: Optional[str] = Field(
        None, description='The id of the parent resource where applicable.\n'
    )
    name: Optional[str] = Field(None, description='The name of the resource.\n')
    description: Optional[str] = Field(
        None, description='A description of the resource.\n'
    )
    tags: Optional[Tags] = None
    commit_info: Optional[ResourceCommitInfo] = None


class ResourceMeta(ResourceMetaSimple, ResourceMetaBase):
    space_id: Optional[SpaceId] = None
    project_id: Optional[ProjectId] = None


class Custom(BaseModel):
    pass

    class Config:
        extra = Extra.allow


class SimpleRel(BaseModel):
    id: str = Field(
        ...,
        description='The id of the referenced resource.\n',
        example='4cedab6d-e8e4-4214-b81a-2ddb122db2ab',
    )


class OnlineDeploymentParameters(BaseModel):
    serving_name: Optional[
        constr(regex=r'^[a-z,0-9,_]+$', min_length=3, max_length=36)
    ] = Field(
        None,
        description='The `serving_name` can be used in the inference URL in place of the `deployment_id`.\n',
        example='churn',
    )


class OnlineDeployment(BaseModel):
    parameters: Optional[OnlineDeploymentParameters] = None


class HardwareSpec(BaseModel):
    id: Optional[str] = Field(
        None,
        description='The id of the hardware specification.\n',
        example='4cedab6d-e8e4-4214-b81a-2ddb122db2ab',
    )
    rev: Optional[str] = Field(
        None, description='The revision of the hardware specification.\n', example='2'
    )
    name: Optional[str] = Field(
        None, description='The name of the hardware specification.\n'
    )
    num_nodes: Optional[int] = Field(
        None, description='The number of nodes applied to a computation.\n', example=2
    )


class Size(Enum):
    gpu_s = 'gpu_s'
    gpu_m = 'gpu_m'


class HardwareRequest(BaseModel):
    size: Optional[Size] = Field(
        None, description='The size of GPU requested for the deployment.\n'
    )
    num_nodes: Optional[float] = Field(
        None, description='The number of nodes for the GPU requested for deployment.\n'
    )


class DeploymentEntityCommon(BaseModel):
    custom: Optional[Custom] = None
    prompt_template: Optional[SimpleRel] = None
    online: OnlineDeployment
    hardware_spec: Optional[HardwareSpec] = None
    hardware_request: Optional[HardwareRequest] = None


class ModelRel(SimpleRel):
    rev: Optional[str] = Field(
        None, description='The revision of the referenced resource.\n', example='2'
    )
    resource_key: Optional[str] = Field(
        None,
        description='The resource key for this asset if it exists.\n',
        example='f52fe20c-a1fe-4e54-9b78-6bf2ff61b455',
    )


class ModelAssetRef(BaseModel):
    asset: Optional[ModelRel] = None


class DeploymentResourceEntity(BaseModel):
    base_model_id: Optional[str] = Field(
        None,
        description='The base model that is required for this deployment if this is for a prompt template or a prompt tune for an IBM foundation model.\n',
        example='google/flan-t5-xl',
    )


class Message(BaseModel):
    level: Optional[str] = Field(
        None,
        description='The level of the message, normally one of `debug`, `info` or `warning`.\n',
        example='info',
    )
    text: Optional[str] = Field(
        None, description='The message.\n', example='The deployment is successful'
    )


class Inference(BaseModel):
    url: str = Field(..., description='The inference URL.\n')
    sse: Optional[bool] = Field(
        False,
        description='This is `true` if the inference API supports SSE streaming.\n',
        example=True,
    )
    uses_serving_name: Optional[bool] = Field(
        False,
        description='This is `true` if the inference API uses the `serving_name` that was defined in this deployment.\n',
        example=True,
    )


class State(Enum):
    initializing = 'initializing'
    updating = 'updating'
    ready = 'ready'
    failed = 'failed'


class DeploymentStatus(BaseModel):
    state: Optional[State] = Field(
        None,
        description='Specifies the current state of the deployment.\n',
        example='ready',
    )
    message: Optional[Message] = None
    failure: Optional[ApiErrorResponse] = None
    inference: Optional[List[Inference]] = Field(
        None,
        description='The URLs that can be used to submit inference API requests. These URLs will contain the\n`deployment_id` and the `serving_name`, if the `serving_name` was set.\n',
        example=[
            {
                'url': 'https://us-south.ml.cloud.ibm.com/ml/v1/deployments/2cd0bcda-581d-4f04-8028-ec2bc90cc375/text/generation'
            },
            {
                'url': 'https://us-south.ml.cloud.ibm.com/ml/v1/deployments/classification/text/generation',
                'uses_serving_name': True,
            },
            {
                'url': 'https://us-south.ml.cloud.ibm.com/ml/v1/deployments/2cd0bcda-581d-4f04-8028-ec2bc90cc375/text/generation_stream',
                'sse': True,
            },
            {
                'url': 'https://us-south.ml.cloud.ibm.com/ml/v1/deployments/classification/text/generation_stream',
                'sse': True,
                'uses_serving_name': True,
            },
        ],
    )


class DeployedAssetType(Enum):
    prompt_tune = 'prompt_tune'
    foundation_model = 'foundation_model'


class DeploymentEntity(DeploymentEntityCommon, ModelAssetRef, DeploymentResourceEntity):
    deployed_asset_type: Optional[DeployedAssetType] = Field(
        None,
        description='The type of the deployed model. The possible values are the following:\n1. `prompt_tune` - when a prompt tuned model is deployed.\n2. `foundation_model` - when a prompt template is used on a pre-deployed IBM provided model.\n',
    )
    verbalizer: Optional[str] = Field(
        None,
        description='The verbalizer that was used to train this model if the deployment\nhas `deployed_asset_type` of `prompt_tune`.\n',
    )
    status: Optional[DeploymentStatus] = None


class DeploymentResource(BaseModel):
    metadata: Optional[ResourceMeta] = None
    entity: Optional[DeploymentEntity] = None


class Stats(BaseModel):
    space_id: Optional[str] = Field(
        None,
        description='An `id` associated with the space.\n',
        example='2fc54cf1-252f-424b-b52d-5cdd98149871',
    )
    total_count: Optional[float] = Field(
        None,
        description='The total number of deployments created in a space including `online` and `batch`.\n',
    )
    online_count: Optional[float] = Field(
        None, description='The number of online deployments created in a space.\n'
    )
    batch_count: Optional[float] = Field(
        None, description='The number of batch deployments created in a space.\n'
    )


class DeploymentSystemDetails(SystemDetails):
    stats: Optional[List[Stats]] = Field(
        None, description='The stats about deployments.\n'
    )


class DeploymentSystem(BaseModel):
    system: Optional[DeploymentSystemDetails] = None


class DeploymentResourceCollection(Pagination):
    resources: Optional[List[DeploymentResource]] = Field(
        None, description='A list of deployment resources.\n'
    )
    system: Optional[DeploymentSystem] = None


class EntityRequestSpaceProjectBody(BaseModel):
    name: str = Field(
        ..., description='The name of the resource.\n', example='my-resource'
    )
    project_id: Optional[ProjectId] = None
    space_id: Optional[SpaceId] = None
    description: Optional[str] = Field(
        None,
        description='A description of the resource.\n',
        example='This is my first resource.',
    )
    tags: Optional[Tags] = None


class Rel(SimpleRel):
    rev: Optional[str] = Field(
        None, description='The revision of the referenced resource.\n', example='2'
    )


class AssetRef(BaseModel):
    asset: Optional[Rel] = None


class DeploymentResourcePrototype(
    EntityRequestSpaceProjectBody,
    DeploymentEntityCommon,
    AssetRef,
    DeploymentResourceEntity,
):
    pass


class Op(Enum):
    add = 'add'
    remove = 'remove'
    replace = 'replace'


class JsonPatchOperation(BaseModel):
    op: Op = Field(..., description='The operation to be performed.\n')
    path: str = Field(
        ...,
        description='The pointer that identifies the field that is the target of the operation.\n',
    )
    value: Optional[str] = Field(
        None, description='The value to be used within the operation.\n'
    )


class JsonPatch(BaseModel):
    __root__: List[JsonPatchOperation] = Field(
        ...,
        description='See [JSON PATCH RFC 6902](https://tools.ietf.org/html/rfc6902).\n',
    )


class CaiKitTextGenProperties(BaseModel):
    typical_p: Optional[confloat(le=1.0, gt=0.0)] = Field(
        None,
        description='Local typicality measures how similar the conditional probability of predicting a target\ntoken next is to the expected conditional probability of predicting a random token next,\ngiven the partial text already generated. If less than 1, the smallest set of the most\nlocally typical tokens with probabilities that add up to typical_p or higher are kept for generation.\n',
        example=0.5,
    )


class TextGenParameters2(TextGenParameters, CaiKitTextGenProperties):
    pass


class PromptVariables(BaseModel):
    __root__: Optional[Dict[str, str]] = None


class PromptTemplateVariables(BaseModel):
    prompt_variables: Optional[PromptVariables] = None


class DeploymentTextGenProperties(TextGenParameters2, PromptTemplateVariables):
    pass


class DeploymentTextGen(BaseModel):
    input: Optional[str] = Field(
        None,
        description='The prompt to generate completions.\nNote: The method tokenizes the input internally.\nIt is recommended not to leave any trailing spaces.\n\n\nThis field is ignored if there is a prompt template.\n',
    )
    parameters: Optional[DeploymentTextGenProperties] = None
    moderations: Optional[Moderations] = None


class DeploymentTextGenRequest(DeploymentTextGen):
    pass


class BaseModelModel(BaseModel):
    model_id: Optional[str] = Field(
        None,
        description='The model id of the base model.\n',
        example='google/flan-t5-xl',
    )


class TuningType(Enum):
    prompt_tuning = 'prompt_tuning'


class InitMethod(Enum):
    random = 'random'
    text = 'text'


class PromptTuning(BaseModel):
    base_model: Optional[BaseModelModel] = None
    task_id: str = Field(
        ...,
        description='The task that is targeted for this model.\n',
        example='summarization',
    )
    tuning_type: Optional[TuningType] = Field(
        'prompt_tuning',
        description='Type of Peft (Parameter-Efficient Fine-Tuning) config to build.\n',
        example='prompt_tuning',
    )
    num_epochs: Optional[conint(ge=1, le=50)] = Field(
        20,
        description='Number of epochs to tune the prompt vectors, this affects the quality of the trained model.\n',
        example=30,
    )
    learning_rate: Optional[confloat(ge=0.01, le=0.5)] = Field(
        0.3,
        description='Learning rate to be used while tuning prompt vectors.\n',
        example=0.4,
    )
    accumulate_steps: Optional[conint(ge=1, le=128)] = Field(
        16,
        description='Number of steps to be used for gradient accumulation.\nGradient accumulation refers to a method of collecting gradient for configured number of\nsteps instead of updating the model variables at every step and then applying the update\nto model variables. This can be used as a tool to overcome smaller batch size limitation.\nOften also referred in conjunction with "effective batch size".\n',
        example=32,
    )
    verbalizer: Optional[str] = Field(
        'Input: {{input}} Output:',
        description='Verbalizer template to be used for formatting data at train and inference time.\nThis template may use brackets to indicate where fields from the data model\nmust be rendered.\n',
        example='rte { 0 : entailment, 1 : not entailment } {{input}}',
    )
    batch_size: Optional[conint(ge=1, le=16)] = Field(
        16,
        description='The batch size is a number of samples processed before the model is updated.\n',
        example=10,
    )
    max_input_tokens: Optional[conint(ge=1, le=256)] = Field(
        256,
        description='Maximum length of input tokens being considered.\n',
        example=100,
    )
    max_output_tokens: Optional[conint(ge=1, le=128)] = Field(
        128,
        description='Maximum length of output tokens being predicted.\n',
        example=100,
    )
    init_method: Optional[InitMethod] = Field(
        'random',
        description='The `text` method requires `init_text` to be set.\n',
        example='text',
    )
    init_text: Optional[str] = Field(
        None,
        description='Initialization text to be used if `init_method` is\nset to `text` otherwise this will be ignored.\n',
    )


class DataConnection(BaseModel):
    pass


class DataLocation(BaseModel):
    __root__: Optional[Dict[str, str]] = None


class DataSchema(BaseModel):
    id: str = Field(..., description='An id to identify a schema.\n', example='t1')
    name: Optional[str] = Field(
        None, description='A name for the schema.\n', example='Tasks'
    )
    fields: List[Dict[str, Any]] = Field(
        ...,
        description='The fields that describe the data schema.\n',
        example=[{'name': 'duration', 'type': 'number'}],
    )
    type: Optional[str] = Field(
        None,
        description='The type of the schema, can be ignored or set to `struct` or `DataFrame`.\n',
        example='struct',
    )


class Type1(Enum):
    connection_asset = 'connection_asset'
    data_asset = 'data_asset'
    container = 'container'
    url = 'url'


class DataConnectionReference(BaseModel):
    id: Optional[str] = Field(
        None,
        description='Optional item identification inside a collection.\n',
        example='8d3682dd-2858-43c9-bfd7-12a79abcfb0c',
    )
    type: Type1 = Field(
        ...,
        description='The data source type like `connection_asset` or `data_asset`.\nIf the data connection contains just a schema then this field is not required.\n',
        example='connection_asset',
    )
    connection: Optional[DataConnection] = None
    location: Optional[DataLocation] = None
    schema_: Optional[DataSchema] = Field(None, alias='schema')


class TrainingResourceEntityCommon(BaseModel):
    prompt_tuning: Optional[PromptTuning] = None
    training_data_references: Optional[List[DataConnectionReference]] = Field(
        None,
        description='Training datasets.\n',
        example=[
            {
                'id': 'tune1_data.json',
                'location': {'path': 'tune1_data.json'},
                'type': 'container',
            }
        ],
    )
    custom: Optional[Custom] = None
    auto_update_model: Optional[bool] = Field(
        False,
        description='If set to `true` then the result of the training, if successful, will be uploaded\nto the repository as a model.\n',
        example=True,
    )


class ObjectLocation(BaseModel):
    id: Optional[str] = Field(
        None, description='Item identification inside a collection.\n'
    )
    type: Type1 = Field(
        ...,
        description='The data source type like `connection_asset` or `data_asset`.\n',
        example='connection_asset',
    )
    connection: Optional[DataConnection] = None
    location: DataLocation


class ResultsReferenceOutput(BaseModel):
    results_reference: ObjectLocation = Field(
        ...,
        description='The training results. Normally this is specified as `type=container` which means that it is stored in the space or project. Note that the training will add some fields that point to the training status, the model request and the assets.\n\nThe `model_request_path` is the request body that should be used when creating the trained model in the API, if this model is to be deployed. If `auto_update_model` was set to `true` then this file is not needed.\n',
        example={
            'location': {
                'path': 'results',
                'training': 'results/360c40f7-ac0c-43ca-a95f-1a5421f93b82',
                'training_status': 'results/360c40f7-ac0c-43ca-a95f-1a5421f93b82/training-status.json',
                'assets_path': 'results/360c40f7-ac0c-43ca-a95f-1a5421f93b82/assets',
                'model_request_path': 'results/360c40f7-ac0c-43ca-a95f-1a5421f93b82/assets/c29e7544-dfd0-4427-bc66-20fa6023e2e0/resources/wml_model/request.json',
            },
            'type': 'container',
        },
    )


class TrainingMLMetrics(BaseModel):
    __root__: Optional[Dict[str, float]] = None


class PromptTuningMetricsContext(BaseModel):
    metrics_location: Optional[str] = Field(
        None, description='The location where the prompt tuning metrics are stored.\n'
    )


class MetricsContext(BaseModel):
    deployment_id: Optional[str] = Field(
        None, description='The deployment that created the metrics.\n'
    )
    prompt_tuning: Optional[PromptTuningMetricsContext] = None


class TrainingMetric(BaseModel):
    timestamp: Optional[datetime] = Field(
        None,
        description='A timestamp for the metrics.\n',
        example='2023-09-22T02:52:03.324Z',
    )
    iteration: Optional[int] = Field(
        None, description='The iteration number.\n', example=0
    )
    ml_metrics: Optional[TrainingMLMetrics] = None
    context: Optional[MetricsContext] = None


class TrainingMetrics(BaseModel):
    __root__: List[TrainingMetric] = Field(
        ...,
        description='Metrics that can be returned by an operation.\n',
        example=[
            {
                'iteration': 0,
                'ml_metrics': {'loss': 4.49988},
                'timestamp': '2023-09-22T02:52:03.324Z',
            },
            {
                'iteration': 1,
                'ml_metrics': {'loss': 3.86884},
                'timestamp': '2023-09-22T02:52:03.689Z',
            },
            {
                'iteration': 2,
                'ml_metrics': {'loss': 4.05115},
                'timestamp': '2023-09-22T02:52:04.053Z',
            },
        ],
    )


class State1(Enum):
    queued = 'queued'
    pending = 'pending'
    running = 'running'
    storing = 'storing'
    completed = 'completed'
    failed = 'failed'
    canceled = 'canceled'


class TrainingStatus(BaseModel):
    running_at: Optional[datetime] = Field(
        None,
        description='Date and Time in which current training state has started.',
        example='2017-01-30T10:11:12Z',
    )
    completed_at: Optional[datetime] = Field(
        None,
        description='Date and Time in which training had completed.',
        example='2017-01-30T10:11:12Z',
    )
    state: State1 = Field(..., description='Current state of training.')
    message: Optional[Message] = None
    metrics: Optional[TrainingMetrics] = None
    failure: Optional[ApiErrorResponse] = None


class TrainingStatusOutput(BaseModel):
    status: TrainingStatus


class TrainingResourceEntity(
    TrainingResourceEntityCommon, ResultsReferenceOutput, TrainingStatusOutput
):
    pass


class TrainingResource(BaseModel):
    metadata: Optional[ResourceMeta] = Field(
        None,
        example={
            'id': '6213cf1-252f-424b-b52d-5cdd9814956c',
            'name': 'my-prompt-training',
            'project_id': '12ac4cf1-252f-424b-b52d-5cdd9814987f',
            'owner': 'guy',
            'created_at': '2023-08-04T13:22:55.289Z',
        },
    )
    entity: Optional[TrainingResourceEntity] = None


class TrainingResourceCollection(Pagination):
    resources: Optional[List[TrainingResource]] = Field(
        None, description='The training resources.\n'
    )
    system: Optional[SystemDetails] = Field(
        None,
        example={
            'warnings': [
                {
                    'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations.',
                    'id': 'DisclaimerWarning',
                }
            ]
        },
    )


class TrainingResourceDetails(BaseModel):
    name: str = Field(
        ..., description='The name of the training.\n', example='my-prompt-training'
    )
    space_id: Optional[SpaceId] = None
    project_id: Optional[ProjectId] = None
    description: Optional[str] = Field(
        None,
        description='A description of the training.\n',
        example='My prompt training.',
    )
    tags: Optional[Tags] = None


class ResultsReferenceInput(BaseModel):
    results_reference: ObjectLocation = Field(
        ...,
        description='The training results. Normally this is specified as `type=container` which\nmeans that it is stored in the space or project.\n',
        example={'location': {'path': 'results'}, 'type': 'container'},
    )


class TrainingResourcePrototype(
    TrainingResourceDetails, TrainingResourceEntityCommon, ResultsReferenceInput
):
    pass


class EmbeddingModelId(BaseModel):
    __root__: str = Field(
        ...,
        description='The `id` of the model to be used for this request.\nPlease refer to the [list of models](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models-embed.html?context=wx&audience=wdp).\n',
    )


class TextInput(BaseModel):
    __root__: str = Field(..., description='The text input to the model.\n')


class ParameterTruncateInputTokensFromEnd(BaseModel):
    __root__: conint(ge=1) = Field(
        ...,
        description='Represents the maximum number of input tokens accepted.\nThis can be used to avoid requests failing due to input being longer than configured limits. If the text is truncated, then it truncates the end of the input (on the right), so the start of the input will remain the same.\nIf this value exceeds the `maximum sequence length` (refer to the documentation to find this value for the model) then the call will fail if the total number of tokens exceeds the `maximum sequence length`.\n',
    )


class EmbeddingReturnOptions(BaseModel):
    input_text: Optional[bool] = Field(
        None,
        description='Include the `input` text in each of the `results` documents.\n',
    )


class EmbeddingParameters(BaseModel):
    truncate_input_tokens: Optional[ParameterTruncateInputTokensFromEnd] = None
    return_options: Optional[EmbeddingReturnOptions] = None


class EmbeddingsRequest(BaseModel):
    space_id: Optional[SpaceId] = None
    project_id: Optional[ProjectId] = None
    model_id: EmbeddingModelId
    inputs: List[TextInput] = Field(
        ..., description='The input text.\n', max_items=1000
    )
    parameters: Optional[EmbeddingParameters] = None


class Embedding(BaseModel):
    input: Optional[TextInput] = None
    embedding: List[float] = Field(
        ..., description='The embedding values.\n', min_items=0
    )


class InputTokenCount(BaseModel):
    __root__: int = Field(
        ..., description='The number of input tokens that were consumed.\n'
    )


class EmbeddingsResponseFields(BaseModel):
    model_id: EmbeddingModelId
    results: List[Embedding] = Field(
        ..., description='The embedding values for a given text.\n', min_items=0
    )
    created_at: CreatedAt
    input_token_count: InputTokenCount


class EmbeddingsResponse(EmbeddingsResponseFields, System):
    pass


class SimilarityResult(BaseModel):
    score: float = Field(
        ..., description='A similarity score between the source and target text.\n'
    )


class SimilarityResponseFields(BaseModel):
    model_id: EmbeddingModelId
    results: List[SimilarityResult] = Field(
        ..., description='The similarity scores.\n', min_items=0
    )
    created_at: CreatedAt
    input_token_count: InputTokenCount


class SimilarityResponse(SimilarityResponseFields, System):
    pass


class RerankInput(BaseModel):
    text: str = Field(..., description='The text to rank.\n')


class RerankQuery(BaseModel):
    __root__: str = Field(..., description='The rank query.\n')


class RerankedResults(BaseModel):
    input: Optional[RerankInput] = None
    score: float = Field(..., description='The score of the input.\n')


class RerankResponseFields(BaseModel):
    model_id: EmbeddingModelId
    query: Optional[RerankQuery] = None
    results: List[RerankedResults] = Field(
        ..., description='The ranked results.\n', min_items=0
    )
    created_at: CreatedAt
    input_token_count: InputTokenCount


class RerankResponse(RerankResponseFields, System):
    pass


class ModerationInputProperties(BaseModel):
    input: Optional[TextModeration] = None


class ModerationHapInputProperties(ModerationInputProperties, HapProperties):
    pass


class ModerationPiiInputProperties(ModerationInputProperties, PiiProperties):
    pass


class CommonPatchRequestHelper(BaseModel):
    tags: Optional[Tags] = None
    name: Optional[str] = Field(
        None, description='The name of the resource.\n', example='my-resource'
    )
    description: Optional[str] = Field(
        None,
        description='A description of the resource.\n',
        example='This is my first resource.',
    )
    custom: Optional[Custom] = None


class TaskId(BaseModel):
    __root__: constr(regex=r'[a-zA-Z0-9-]*')


class InputMode(Enum):
    structured = 'structured'
    freeform = 'freeform'
    chat = 'chat'
    detached = 'detached'


class ModelVersion(BaseModel):
    number: Optional[
        constr(
            regex=r'^(0|[1-9]\d*)\.(0|[1-9]\d*)\.(0|[1-9]\d*)(?:-((?:0|[1-9]\d*|\d*[a-zA-Z-][0-9a-zA-Z-]*)(?:\.(?:0|[1-9]\d*|\d*[a-zA-Z-][0-9a-zA-Z-]*))*))?(?:\+([0-9a-zA-Z-]+(?:\.[0-9a-zA-Z-]+)*))?$'
        )
    ] = Field(
        None,
        description='User provided semantic version for tracking in IBM AI Factsheets',
        example='2.0.0-rc.7',
    )
    tag: Optional[constr(regex=r'.*')] = Field(
        None, description='User provived tag.', example='tag'
    )
    description: Optional[constr(regex=r'.*')] = Field(
        None,
        description='Description of the version.',
        example='Description of the model version.',
    )


class TaskId2(BaseModel):
    __root__: constr(regex=r'[a-zA-Z0-9-]*') = Field(..., example='generation')


class InputMode2(Enum):
    structured = 'structured'
    freeform = 'freeform'


class InputMode3(Enum):
    structured = 'structured'
    freeform = 'freeform'
    chat = 'chat'


class Result1(BaseModel):
    id: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description="The prompt entry's ID",
        example='1c29d9a1-9ba6-422d-aa39-517b26adc147',
    )
    name: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None, description="The prompt entry's name", example='Name of an entry'
    )
    description: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description="The prompt entry's description",
        example='Description of an entry',
    )
    created_at: Optional[int] = Field(
        None,
        description="The prompt entry's create time in millis",
        example=1711504485261,
    )


class WxPromptSessionEntryList(BaseModel):
    class Config:
        extra = Extra.forbid

    results: Optional[List[Result1]] = None
    bookmark: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = None


class InputItem(BaseModel):
    __root__: constr(regex=r'[a-zA-Z0-9-]*')


class ModelParameters(BaseModel):
    decoding_method: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = None
    max_new_tokens: Optional[int] = None
    min_new_tokens: Optional[int] = None
    random_seed: Optional[int] = None
    stop_sequences: Optional[List[constr(regex=r'[a-zA-Z0-9-]*')]] = None
    temperature: Optional[float] = None
    top_k: Optional[float] = None
    top_p: Optional[float] = None
    repetition_penalty: Optional[float] = None


class ExternalModel(BaseModel):
    class Config:
        extra = Extra.forbid

    name: constr(regex=r'.*')
    url: constr(regex=r'.*')


class ExternalPromptAdditionalInformation1(BaseModel):
    class Config:
        extra = Extra.forbid

    key: Optional[constr(regex=r'^[\s\S]{0,250}$')] = None


class ExternalPromptAdditionalInformation(BaseModel):
    __root__: List[ExternalPromptAdditionalInformation1] = Field(
        ..., example=[{'key': 'value'}, {'key': 'value'}]
    )


class Type3(Enum):
    question = 'question'
    answer = 'answer'


class Status(Enum):
    ready = 'ready'
    error = 'error'


class ChatItem(BaseModel):
    class Config:
        extra = Extra.forbid

    type: Optional[Type3] = None
    content: Optional[constr(regex=r'.*')] = Field(None, example='Some text')
    status: Optional[Status] = None
    timestamp: Optional[int] = Field(None, example=1711504485261)


class Example(BaseModel):
    __root__: constr(regex=r'^[\s\S]*')


class PromptData(BaseModel):
    class Config:
        extra = Extra.forbid

    instruction: Optional[constr(regex=r'[\s\S]*')] = None
    input_prefix: Optional[constr(regex=r'[\s\S]*')] = None
    output_prefix: Optional[constr(regex=r'[\s\S]*')] = None
    examples: Optional[List[List[Example]]] = []


class LockType(Enum):
    edit = 'edit'
    governance = 'governance'


class PromptLock(BaseModel):
    class Config:
        extra = Extra.forbid

    locked: bool = Field(..., description='True if the prompt is currently locked.')
    lock_type: Optional[LockType] = Field(
        None,
        description="Lock type: 'edit' for working on prompts/templates or 'governance'. Can only be supplied in PUT /lock requests.",
    )
    locked_by: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description="Locked by is computed by the server and shouldn't be passed.",
        example='IBMid-000000YYY0',
    )


class PromptVariable(BaseModel):
    pass

    class Config:
        extra = Extra.allow


class PromptVariableString(BaseModel):
    __root__: constr(regex=r'[a-zA-Z0-9-]*') = Field(..., example='var1')


class NotebookMetadata(BaseModel):
    name: Optional[str] = Field(
        None, description='The name of the notebook.', example='my notebook'
    )
    description: Optional[str] = Field(
        None, description='A more verbose description.', example='this is my notebook'
    )
    asset_type: Optional[str] = Field(
        None, description='Asset type, always "notebook".', example='notebook'
    )
    created: Optional[int] = Field(
        None, description='Creation date, ms since epoch.', example=1540471021134
    )
    created_at: Optional[str] = Field(
        None, description='Creation date, ISO format.', example='2018-10-25T12:37:01Z'
    )
    owner_id: Optional[str] = Field(
        None, description="IAM ID of the asset's owner.", example='IBMid-310000SG2Y'
    )
    catalog_id: Optional[str] = Field(
        None,
        description="UUID of the asset's catalog.",
        example='463cb8d8-8480-4a98-b75a-f7443b7d0af9',
    )
    asset_id: Optional[str] = Field(
        None,
        description='UUID of the asset.',
        example='41d09a9a-f771-48a2-9534-50c0c622356d',
    )


class NotebookMetadataInProject(NotebookMetadata):
    project_id: str = Field(
        ...,
        description="UUID of the asset's project.",
        example='b275be5f-10ff-47ee-bfc9-63f1ce5addbf',
    )


class NotebookResourceMetadata(BaseModel):
    guid: Optional[str] = Field(
        None,
        description='UUID of the notebook.',
        example='299993bf-9a42-48ae-aadd-1336f31d5556',
    )
    url: Optional[str] = Field(
        None,
        description='URL of the notebook.',
        example='/v2/notebooks/299993bf-9a42-48ae-aadd-1336f31d5556',
    )


class NotebookResourceEntityAsset(BaseModel):
    asset_id: Optional[str] = Field(
        None,
        description='The UUID of the asset.',
        example='41d09a9a-f771-48a2-9534-50c0c622356d',
    )
    asset_type: Optional[str] = Field(
        None, description='The asset type. Always "notebook".', example='notebook'
    )
    created: Optional[int] = Field(
        None,
        description='Timestamp of the creation date, ms since epoch.',
        example=1540471021134,
    )
    created_at: Optional[str] = Field(
        None,
        description='Date the asset was created, ISO format.',
        example='2018-10-25T12:37:01Z',
    )
    catalog_id: Optional[str] = Field(
        None,
        description='The asset catalog ID.',
        example='463cb8d8-8480-4a98-b75a-f7443b7d0af9',
    )
    project_id: Optional[str] = Field(
        None,
        description='The project the notebook belongs to.',
        example='b275be5f-10ff-47ee-bfc9-63f1ce5addbf',
    )
    version: Optional[int] = Field(None, description='Version of the asset.', example=2)
    href: Optional[str] = Field(
        None,
        description='The asset URL.',
        example='/v2/assets/299993bf-9a42-48ae-aadd-1336f31d5556?project_id=850d08c4-31f1-4722-a7ef-eeefd796e995',
    )


class NotebookResourceEntityRuntime(BaseModel):
    spark_monitoring_enabled: Optional[bool] = Field(
        None, description='If Spark monitoring is enabled.', example=True
    )
    environment: Optional[str] = Field(
        None,
        description='UUID of the environment of the notebook.',
        example='conda4x16-850d08c4-31f1-4722-a7ef-eeefd796e995',
    )


class NotebookCopyBody(BaseModel):
    name: str = Field(
        ..., description='The name of the new notebook.', example='my notebook'
    )
    source_guid: str = Field(
        ...,
        description='The guid of the notebook to be copied.',
        example='ca3c0e27-46ca-83d4-a646-d49b11c14de9',
    )


class NotebookRevertBody(BaseModel):
    source: str = Field(
        ...,
        description='The guid of the notebook version.',
        example='ca3c0e27-46ca-83d4-a646-d49b11c14de9',
    )


class NotebookOrigin(BaseModel):
    type: Optional[str] = Field(
        None,
        description='The orgin type of the notebook, either blank, file or url.',
        example='blank',
    )


class NotebookOriginFromSource(BaseModel):
    type: Optional[str] = Field(
        None,
        description='The orgin type of the notebook, either blank, file or url.',
        example='notebook',
    )
    guid: Optional[str] = Field(
        None,
        description='The guid of the source file',
        example='ca3c0e27-46ca-83d4-a646-d49b11c14de9',
    )


class NotebookRuntime(BaseModel):
    environment: str = Field(
        ...,
        description='The guid of the environment on which the notebook runs.',
        example='conda4x16-d46ca0e27-a646-4de9-a646-9b113c183d4',
    )
    spark_monitoring_enabled: Optional[bool] = Field(
        None, description='Spark monitoring enabled or not.'
    )


class NotebookKernel(BaseModel):
    display_name: Optional[str] = Field(
        None,
        description='The display name of the environment kernel.',
        example='Python 3.9 with Spark',
    )
    name: Optional[str] = Field(
        None, description='The name of the environment kernel.', example='python3'
    )
    language: Optional[str] = Field(
        None, description='The language of the environment kernel.', example='python3'
    )


class NotebookListBody(BaseModel):
    notebooks: Optional[List[str]] = Field(
        None, description='The list of notebooks whose details will be retrieved.'
    )


class NotebookUpdateBody(BaseModel):
    environment: Optional[str] = Field(
        None,
        description='The guid of the environment on which the notebook runs.',
        example='d46ca0e27-a646-4de9-a646-9b113c183d4',
    )
    spark_monitoring_enabled: Optional[bool] = Field(
        None, description='Spark monitoring enabled or not.', example=False
    )
    kernel: Optional[NotebookKernel] = None


class NotebookVersionMetadata(BaseModel):
    guid: Optional[str] = Field(
        None,
        description='The guid of the version.',
        example='19d63b6b-81a1-4c05-bad2-36a2957bd6d0',
    )
    url: Optional[str] = Field(
        None,
        description='The URL of the version.',
        example='v2/notebooks/a528b427-d1cd-4039-8ddc-04203c2521e2/versions/1a1329e0-fd05-409a-8411-52db106e2142',
    )
    created_at: Optional[int] = Field(
        None,
        description='The creation timestamp in UTC millisecond since UNIX Epoch time.',
        example=1543681714106,
    )


class NotebookVersionEntity(BaseModel):
    master_notebook_guid: Optional[str] = Field(
        None,
        description='The guid of the versioned notebook.',
        example='a528b427-d1cd-4039-8ddc-04203c2521e2',
    )
    created_by_iui: Optional[str] = Field(
        None,
        description='The IUI of the user that has created the version.',
        example='IBMid-123456ABCD',
    )
    file_reference: Optional[str] = Field(
        None,
        description='The file reference in the corresponding COS.',
        example='myproject-donotdelete-pr-6p65nym92j1bv0/notebooks/GPU_ENVIRONMENT_DEFAULT_GBUXVKHH_version_1543781324804.ipynb',
    )
    rev_id: Optional[int] = Field(
        None, description='The revision id of the notebook.', example=1
    )


class NotebookVersionEntityInProject(NotebookVersionEntity):
    project_id: str = Field(
        ...,
        description='The guid of the project.',
        example='0f7c1111-a79d-45b2-9699-d4950e742964',
    )


class Type4(Enum):
    field = 'field'
    query = 'query'
    header = 'header'


class ErrorTarget(BaseModel):
    type: Type4 = Field(..., description='The type of the problematic field.')
    name: str = Field(..., description='The name of the problematic field.')


class DeploymentResourcePatch(CommonPatchRequestHelper):
    asset: Optional[Rel] = None


class Prompt(BaseModel):
    class Config:
        extra = Extra.forbid

    input: Optional[List[List[InputItem]]] = []
    model_id: constr(regex=r'[a-zA-Z0-9-//]*') = Field(
        ..., example='ibm/granite-13b-chat-v2'
    )
    model_parameters: Optional[ModelParameters] = None
    data: PromptData
    system_prompt: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = None
    chat_items: Optional[List[ChatItem]] = None


class ExternalPrompt(BaseModel):
    class Config:
        extra = Extra.forbid

    url: constr(regex=r'.*')
    additional_information: Optional[List[ExternalPromptAdditionalInformation]] = Field(
        None, min_items=1
    )


class ExternalInformation(BaseModel):
    class Config:
        extra = Extra.forbid

    external_prompt_id: constr(regex=r'.*')
    external_model_id: constr(regex=r'.*')
    external_model_provider: constr(regex=r'.*')
    external_prompt: Optional[ExternalPrompt] = None
    external_model: Optional[ExternalModel] = None


class WxPromptInputRequest(BaseModel):
    class Config:
        extra = Extra.forbid

    input: Optional[constr(regex=r'.*')] = Field(
        None,
        description='Override input string that will be used to generate the response. The string can contain template parameters.',
        example='Some text with variables.',
    )
    prompt_variables: Optional[Dict[str, PromptVariableString]] = Field(
        None,
        description="Supply only to replace placeholders. Object content must be key:value pairs where the 'key' is the parameter to replace and 'value' is the value to use.",
    )


class NotebookEntityDefinition(BaseModel):
    kernel: Optional[NotebookKernel] = None
    originates_from: Optional[NotebookOrigin] = None


class NotebookEntityDefinitionForCopy(BaseModel):
    kernel: Optional[NotebookKernel] = None
    originates_from: Optional[NotebookOriginFromSource] = None


class NotebookResourceEntity(BaseModel):
    asset: Optional[NotebookResourceEntityAsset] = None
    runtime: Optional[NotebookResourceEntityRuntime] = None


class NotebookCreateBodyGeneral(BaseModel):
    name: str = Field(
        ..., description='The name of the new notebook.', example='my notebook'
    )
    description: Optional[str] = Field(
        None,
        description='A more verbose description of the notebook.',
        example='this is my notebook',
    )
    file_reference: str = Field(
        ...,
        description='The reference to the file in the object storage.',
        example='notebook/my_notebook.ipynb',
    )
    originates_from: Optional[NotebookOrigin] = None
    runtime: NotebookRuntime
    kernel: Optional[NotebookKernel] = None


class NotebookVersionInProject(BaseModel):
    metadata: Optional[NotebookVersionMetadata] = None
    entity: Optional[NotebookVersionEntityInProject] = None


class NotebookVersionsListInProject(BaseModel):
    total_results: int = Field(
        ..., description='The number of items in the resources array.', example=1
    )
    resources: List[NotebookVersionInProject] = Field(
        ..., description='An array of notebook versions.'
    )


class Error(BaseModel):
    code: str = Field(..., description='The code describing the error.')
    message: str = Field(..., description='The detailed information about the error.')
    target: Optional[ErrorTarget] = None


class WxPromptPatch(BaseModel):
    class Config:
        extra = Extra.forbid

    id: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description="The prompt's id. This value cannot be set. It is returned in responses only.",
        example='1c29d9a1-9ba6-422d-aa39-517b26adc147',
    )
    name: constr(regex=r'[a-zA-Z0-9-]*') = Field(
        ..., description='Name used to display the prompt.', example='My Prompt'
    )
    description: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description='An optional description for the prompt.',
        example='My First Prompt',
    )
    task_ids: Optional[List[TaskId2]] = Field(None, max_items=1, min_items=1)
    governance_tracked: Optional[bool] = None
    model_version: Optional[ModelVersion] = None
    prompt_variables: Optional[Dict[str, PromptVariable]] = None
    input_mode: Optional[InputMode2] = Field(
        None, description='Input mode in use for the prompt'
    )
    prompt: Prompt


class WxPromptSessionEntry(BaseModel):
    class Config:
        extra = Extra.forbid

    id: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description="The prompt's id. This value cannot be set. It is returned in responses only.",
        example='1c29d9a1-9ba6-422d-aa39-517b26adc147',
    )
    name: constr(regex=r'[a-zA-Z0-9-]*') = Field(
        ..., description='Name used to display the prompt.', example='My Prompt'
    )
    description: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description='An optional description for the prompt.',
        example='My First Prompt',
    )
    prompt_variables: Optional[Dict[str, PromptVariable]] = None
    is_template: Optional[bool] = None
    created_at: int = Field(
        ..., description='Time the prompt was created.', example=1711504485261
    )
    input_mode: Optional[InputMode3] = Field(
        None, description='Input mode in use for the prompt'
    )
    prompt: Prompt


class PromptWithExternal(BaseModel):
    class Config:
        extra = Extra.forbid

    input: Optional[List[List[InputItem]]] = []
    model_id: constr(regex=r'[a-zA-Z0-9-//]*') = Field(
        ..., example='ibm/granite-13b-chat-v2'
    )
    model_parameters: Optional[ModelParameters] = None
    data: PromptData
    system_prompt: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = None
    chat_items: Optional[List[ChatItem]] = None
    external_information: Optional[ExternalInformation] = None


class NotebookEntity(BaseModel):
    notebook: Optional[NotebookEntityDefinition] = None
    runtime: Optional[NotebookRuntime] = None
    href: Optional[str] = Field(
        None,
        description='Full URI of the notebook.',
        example='/v2/assets/41d09a9a-f771-48a2-9534-50c0c622356d?project_id=b275be5f-10ff-47ee-bfc9-63f1ce5addbf',
    )


class NotebookEntityForCopy(BaseModel):
    notebook: Optional[NotebookEntityDefinitionForCopy] = None
    runtime: Optional[NotebookRuntime] = None
    href: Optional[str] = Field(
        None,
        description='Full URI of the notebook.',
        example='/v2/assets/41d09a9a-f771-48a2-9534-50c0c622356d?project_id=b275be5f-10ff-47ee-bfc9-63f1ce5addbf',
    )


class NotebookResource(BaseModel):
    metadata: Optional[NotebookResourceMetadata] = None
    entity: Optional[NotebookResourceEntity] = None


class NotebookCreateBodyInProject(NotebookCreateBodyGeneral):
    project: str = Field(
        ...,
        description='The guid of the project in which to create the notebook.',
        example='92ae0e27-9b11-4de9-a646-d46ca3c183d4',
    )


class ErrorResponse(BaseModel):
    trace: str = Field(..., description='The trace ID used in logs.')
    errors: List[Error] = Field(..., description='The error objects.')


class WxPromptResponse(BaseModel):
    class Config:
        extra = Extra.forbid

    id: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description="The prompt's id. This value cannot be set. It is returned in responses only.",
        example='1c29d9a1-9ba6-422d-aa39-517b26adc147',
    )
    name: constr(regex=r'[a-zA-Z0-9-]*') = Field(
        ..., description='Name used to display the prompt.', example='My Prompt'
    )
    description: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description='An optional description for the prompt.',
        example='My First Prompt',
    )
    created_at: Optional[int] = Field(
        None, description='Time the prompt was created.', example=1711504485261
    )
    created_by: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description='The ID of the original prompt creator.',
        example='IBMid-000000YYY0',
    )
    last_updated_at: Optional[int] = Field(
        None, description='Time the prompt was updated.', example=1711504485261
    )
    last_updated_by: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description='The ID of the last user that modifed the prompt.',
        example='IBMid-000000YYY0',
    )
    task_ids: Optional[List[TaskId]] = Field(None, max_items=1, min_items=1)
    governance_tracked: Optional[bool] = None
    lock: Optional[PromptLock] = None
    input_mode: Optional[InputMode] = Field(
        None, description='Input mode in use for the prompt'
    )
    model_version: Optional[ModelVersion] = None
    prompt_variables: Optional[Dict[str, PromptVariable]] = None
    is_template: Optional[bool] = None
    resource_key: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = None
    prompt: PromptWithExternal


class WxPromptPost(BaseModel):
    class Config:
        extra = Extra.forbid

    name: constr(regex=r'[a-zA-Z0-9-]*') = Field(
        ..., description='Name used to display the prompt.', example='My Prompt'
    )
    description: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description='An optional description for the prompt.',
        example='My First Prompt',
    )
    created_at: Optional[int] = Field(
        None, description='Time the prompt was created.', example=1711504485261
    )
    task_ids: Optional[List[TaskId]] = Field(None, max_items=1, min_items=1)
    lock: Optional[PromptLock] = None
    model_version: Optional[ModelVersion] = None
    prompt_variables: Optional[Dict[str, PromptVariable]] = None
    input_mode: Optional[InputMode] = Field(
        None, description='Input mode in use for the prompt'
    )
    prompt: PromptWithExternal


class WxPromptSession(BaseModel):
    class Config:
        extra = Extra.forbid

    id: Optional[constr(regex=r'[a-zA-Z0-9-]{32}')] = Field(
        None,
        description="The prompt session's id. This value cannot be set. It is returned in responses only.",
        example='1c29d9a1-9ba6-422d-aa39-517b26adc147',
    )
    name: constr(regex=r'^.{0,100}$') = Field(
        ..., description='Name used to display the prompt session.', example='Session 1'
    )
    description: Optional[constr(regex=r'^[\s\S]{0,250}')] = Field(
        None,
        description='An optional description for the prompt session.',
        example='My First Prompt Session',
    )
    created_at: Optional[int] = Field(
        None, description='Time the session was created.', example=1711504485261
    )
    created_by: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description='The ID of the original session creator.',
        example='IBMid-000000YYY0',
    )
    last_updated_at: Optional[int] = Field(
        None, description='Time the session was updated.', example=1711504485261
    )
    last_updated_by: Optional[constr(regex=r'[a-zA-Z0-9-]*')] = Field(
        None,
        description='The ID of the last user that modifed the session.',
        example='IBMid-000000YYY0',
    )
    lock: Optional[PromptLock] = None
    prompts: Optional[List[WxPromptSessionEntry]] = Field(
        None, max_items=50, min_items=0
    )


class NotebookInProject(BaseModel):
    metadata: Optional[NotebookMetadataInProject] = None
    entity: Optional[NotebookEntity] = None


class NotebooksResourceList(BaseModel):
    total_results: int = Field(
        ..., description='The number of items in the resources list.', example=1
    )
    resources: List[NotebookResource] = Field(..., description='An array of notebooks.')


class Notebook(BaseModel):
    metadata: Optional[NotebookMetadata] = None
    entity: Optional[NotebookEntity] = None


class NotebookForCopy(BaseModel):
    metadata: Optional[NotebookMetadataInProject] = None
    entity: Optional[NotebookEntityForCopy] = None
